dataset: cifar10
model: mlp
feat_dim: 3
img_size: 32
learning_rate: 0.003
weight_decay: 0.00005
classes: 10
epochs: 10
train_batch_size: 16384
test_batch_size: 8192
val_freq: 1
uncert_epochs: 30
uncert_batch_size: 8192
resume:
test_path: cifar10_mlp_model_best.pth
patience: 7
